{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer #for word embedding\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix,precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,recall_score # bag of words\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import itertools\n",
    "import collections\n",
    "import csv\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "import numpy as np #for text pre-processing\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "import re, string\n",
    "import seaborn\n",
    "import string\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')#for model-building\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_labels_and_sentences(textfile, labelfile):\n",
    "\n",
    "    # read textfile and labelfile into two separate dataframes\n",
    "    df_text = pd.read_csv(textfile + '.txt', header=None, skiprows = 0,\n",
    "        names=['tweet'], sep='\\t', quoting=3)\n",
    "    df_labels = pd.read_csv(labelfile + '.txt',header=None, skiprows = 0, names=['label'],\n",
    "        sep='\\t', quoting=3)\n",
    "\n",
    "    index_text = [x for x in range(1, len(df_text.values)+1)]\n",
    "\n",
    "    df_labels.insert(loc=0, column='id', value =index_text)\n",
    "    df_text.insert(loc=0, column='id', value =index_text)\n",
    "    final_df = df_text.merge(df_labels, on='id', how='left')\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def missing_values(dataframe):\n",
    "    res = dataframe.isna().sum()\n",
    "    return res\n",
    "\n",
    "def word_count(dataframe_col):\n",
    "    dataframe_col['word_count'] = dataframe_col['tweet'].apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    avg_off_tweets = round(dataframe_col[dataframe_col['label']==1]['word_count'].mean(),3)\n",
    "    avg_non_off_tweets = round(dataframe_col[dataframe_col['label']==0]['word_count'].mean(),3) \n",
    "\n",
    "    return dataframe_col, avg_off_tweets, avg_non_off_tweets\n",
    "# CHARACTER-COUNT\n",
    "def char_count(dataframe_col):\n",
    "    dataframe_col['char_count'] = dataframe_col['tweet'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    #the average characters in offensive tweets\n",
    "    avg_char_off = round(dataframe_col[dataframe_col['label']==1]['char_count'].mean(),3) \n",
    "\n",
    "    #the average characters in non-offensive tweets\n",
    "    avg_char_non_off = round(dataframe_col[dataframe_col['label']==0]['char_count'].mean(),3)\n",
    "\n",
    "    return dataframe_col, avg_char_off, avg_char_non_off\n",
    "\n",
    "def class_distribution(dataframe,title,xlabel_title):\n",
    "    x = dataframe['label'].value_counts()\n",
    "    barplot = seaborn.barplot(x.index, x)\n",
    "    barplot.set_title(title)\n",
    "    barplot.set_xlabel(xlabel_title)\n",
    "    barplot.set_ylabel(\"Count\")\n",
    " \n",
    "    return barplot\n",
    "def plot_word_count(dataframe):\n",
    "    # PLOTTING WORD-COUNT\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,4))\n",
    "    dataframe_words=dataframe[dataframe['label']==1]['word_count']\n",
    "    ax1.hist(dataframe_words,color='red')\n",
    "    ax1.set_title('offensive tweets')\n",
    "    dataframe_words=dataframe[dataframe['label']==0]['word_count']\n",
    "    ax2.hist(dataframe_words,color='green')\n",
    "    ax2.set_title('non-offensive tweets')\n",
    "    fig.suptitle('Words per tweet')\n",
    "    ax2.set_xlabel(\"Length of tweet\")\n",
    "    ax2.set_ylabel(\"occurrences\")\n",
    "    ax1.set_xlabel(\"Length of tweet\")\n",
    "    ax1.set_ylabel(\"occurrences\")\n",
    "    fig.savefig('word_count_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "def split_dataset(dataframe):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataframe[\"tweet\"],dataframe      \n",
    "    [\"label\"],test_size=0.2,shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def tokenize_train_test(X_train, X_test):\n",
    "    #Word2Vec\n",
    "    # Word2Vec runs on tokenized sentences\n",
    "    X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "    X_test_tok= [nltk.word_tokenize(i) for i in X_test]\n",
    "\n",
    "    return X_train_tok, X_test_tok\n",
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.word2vec[w] \n",
    "        for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0) \n",
    "        for words in X])\n",
    "def create_bag_of_words(X):\n",
    "\n",
    "    print ('Creating bag of words...')\n",
    "    # Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "    # bag of words tool.  \n",
    "    \n",
    "    # In this example features may be single words or two consecutive words\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = None,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = None,   \\\n",
    "                                 ngram_range = (1,2), \\\n",
    "                                 max_features = 10000) \n",
    "\n",
    "    # fit_transform() does two functions: First, it fits the model\n",
    "    # and learns the vocabulary; second, it transforms our training data\n",
    "    # into feature vectors. The input to fit_transform should be a list of \n",
    "    # strings. The output is a sparse array\n",
    "    train_data_features = vectorizer.fit_transform(X)\n",
    "    \n",
    "    # Convert to a NumPy array for easy of handling\n",
    "    train_data_features = train_data_features.toarray()\n",
    "    \n",
    "    # tfidf transform\n",
    "    \n",
    "    tfidf = TfidfTransformer()\n",
    "    tfidf_features = tfidf.fit_transform(train_data_features).toarray()\n",
    "\n",
    "    # Take a look at the words in the vocabulary\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "   \n",
    "    return vectorizer, vocab, train_data_features, tfidf_features, tfidf\n",
    "def train_logistic_regression(features, label):\n",
    "    print (\"Training the logistic regression model...\")\n",
    "\n",
    "    ml_model = LogisticRegression(C = 100,random_state = 0)\n",
    "    ml_model.fit(features, label)\n",
    "    print ('Finished')\n",
    "    return ml_model\n",
    "\n",
    "\n",
    "\n",
    "def get_word2vec_embeddings(vectors, clean_questions_tokens, generate_missing=False):\n",
    "    embeddings = clean_questions_tokens.apply(lambda x: get_average_word2vec(x, vectors, \n",
    "                                                                                generate_missing=generate_missing))\n",
    "    return list(embeddings)\n",
    "\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.winter):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize=20)\n",
    "    plt.yticks(tick_marks, classes, fontsize=20)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] < thresh else \"black\", fontsize=40)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=30)\n",
    "    plt.xlabel('Predicted label', fontsize=30)\n",
    "    plt.savefig('confusion_matrix' + title +'.png')\n",
    "    return plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offensive dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merging_labels_and_sentences('datasets/offensive/train_text', 'datasets/offensive/train_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_val = missing_values(train_df)\n",
    "# Average words devided into labels\n",
    "avg_labels_word = word_count(train_df)\n",
    "avg_labels_char = char_count(train_df)\n",
    "\n",
    "print(' Average Number of Words - Offensive Tweets: ', avg_labels_word[1],'\\n','Average Number of Words - Non-offensive Tweets: ', avg_labels_word[2])\n",
    "print(' Average Characters in Offensive Tweets: ', avg_labels_char[1],'\\n','Average Characters in Non-offensive Tweets: ', avg_labels_char[2])\n",
    "\n",
    "print('\\nNumber of missing values for each column\\n',missing_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of total labels for each class: 0 = non offensive, 1 = offensive\n",
    "barplot = class_distribution(train_df,\"Count of each label\",\"0: Non offensive   1: Offensive\")\n",
    "# Histogram of Word count pr tweet\n",
    "plot_word_count = plot_word_count(train_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = merging_labels_and_sentences('datasets/offensive/test_text', 'datasets/offensive/test_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency-Inverse Document Frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency-Inverse Document Frequencies (tf-Idf): Count vectors might not be the best representation for converting text data to numerical data. So, instead of simple counting, we can also use an advanced variant of the Bag-of-Words that uses the term frequencyâ€“inverse document frequency (or Tf-Idf). Basically, the value of a word increases proportionally to count in the document, but it is inversely proportional to the frequency of the word in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we are splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df['tweet']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df[\"tweet\"]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we tokenize the data\n",
    "X_train_tok, X_test_tok = tokenize_train_test(X_train, X_test)\n",
    "\n",
    "\n",
    "# (tf-Idf)\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# (#W2v)\n",
    "w2v_X_train_tok=[nltk.word_tokenize(i) for i in X_train]\n",
    "model = gensim.models.Word2Vec(w2v_X_train_tok,min_count=1)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv))      \n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_test_vectors_w2v = modelw.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, vocab, train_data_features, tfidf_features, tfidf  = (\n",
    "        create_bag_of_words(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model = train_logistic_regression(tfidf_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(X_test)\n",
    "# Convert to numpy array\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = ml_model.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_identified_y = predicted_y == y_test\n",
    "accuracy = np.mean(correctly_identified_y) * 100\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, predicted_y)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "source": [
    "### Summary \n",
    "\n",
    "Testing the Bag of Words implementation combined with tf-idf in the model for Logistic Regression shows Accuracy at _0.50 or 50 %_ and therefore we decided to not test the BOW + tf-idf on other classifier models since BOW + w2v gives much better results for all classifiers (logistic regression, linear svc, naive bayes, random forest)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words - Word2Vec\n",
    "\n",
    "***"
   ]
  },
  {
   "source": [
    "#### Creating the model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer='word', token_pattern=r'\\w+')\n",
    "\n",
    "bow = dict()\n",
    "bow[\"train\"] = (count_vectorizer.fit_transform(X_train), y_train)\n",
    "bow[\"test\"]  = (count_vectorizer.transform(X_test), y_test)"
   ]
  },
  {
   "source": [
    "#### Classifers and imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#log reg\n",
    "lr_classifier = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', random_state=40)\n",
    "\n",
    "#linear svc\n",
    "lsvm_classifier = LinearSVC(C=1.0, class_weight='balanced', multi_class='ovr', random_state=40)\n",
    "\n",
    "#naive bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "#random forest \n",
    "clf_bow = RandomForestClassifier(n_estimators = 40)\n",
    "\n",
    "#data set in bag of words\n",
    "embedding = bow"
   ]
  },
  {
   "source": [
    "#### a) Classifier: Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = lr_classifier     \n",
    "# lr_classifier \n",
    "\n",
    "classifier.fit(*embedding[\"train\"])\n",
    "y_predict = classifier.predict(embedding[\"test\"][0])\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(embedding[\"test\"][1], y_predict)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(embedding[\"test\"][1], y_predict)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "#plot = plot_confusion_matrix(cm, classes=['Non-Offensive','Offensive'], normalize=False, title='Confusion matrix')\n",
    "#plt.show()\n"
   ]
  },
  {
   "source": [
    "#### b) Classifier: Linear Support Vector Machine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = lsvm_classifier    \n",
    "# lsvm_classifier \n",
    "\n",
    "classifier.fit(*embedding[\"train\"])\n",
    "y_predict = classifier.predict(embedding[\"test\"][0])\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(embedding[\"test\"][1], y_predict)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(embedding[\"test\"][1], y_predict)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "#plot = plot_confusion_matrix(cm, classes=['Non-Offensive','Offensive'], normalize=False, title='Confusion matrix')\n",
    "#plt.show()"
   ]
  },
  {
   "source": [
    "#### C) Classifier: Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = nb_classifier    \n",
    "# lr_classifier | lsvm_classifier | nb_classifier\n",
    "\n",
    "classifier.fit(*embedding[\"train\"])\n",
    "y_predict = classifier.predict(embedding[\"test\"][0])\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(embedding[\"test\"][1], y_predict)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(embedding[\"test\"][1], y_predict)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "#plot = plot_confusion_matrix(cm, classes=['Non-Offensive','Offensive'], normalize=False, title='Confusion matrix')\n",
    "#plt.show()"
   ]
  },
  {
   "source": [
    "#### d) Classifier: Random Forest Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = clf_bow    \n",
    "# lr_classifier | lsvm_classifier | nb_classifier\n",
    "\n",
    "classifier.fit(*embedding[\"train\"])\n",
    "y_predict = classifier.predict(embedding[\"test\"][0])\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(embedding[\"test\"][1], y_predict)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(embedding[\"test\"][1], y_predict)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "#plot = plot_confusion_matrix(cm, classes=['Non-Offensive','Offensive'], normalize=False, title='Confusion matrix')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Random Forest Classifier with Bag of Words as input gives the best results compared to the other models:\n",
    " \n",
    "- Accuracy at _0.801 or 80 %_ \n",
    "- Recall value at _0.801 or 80 %_ \n",
    "- F1-score at _0.773 or 77 %_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Logistic Regression (sgdc)\n",
    "\n",
    "1. Feature Extraction Technique: tf-idf\n",
    "2. Feature Extraction Technique: w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) sgdc with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use classification algorithm (i.e. Stochastic Logistic Regression) \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr_sgdc_tf = SGDClassifier(loss='log', penalty='l1')\n",
    "lr_sgdc_tf.fit(X_train_vectors_tfidf, y_train)\n",
    "\n",
    "print(lr_sgdc_tf.score(X_train_vectors_tfidf, y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred_probas_lr_sgdc_tf = lr_sgdc_tf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "fpr_lr_sgdc_tf, tpr_lr_sgdc_tf,  thresholds_lr_sgdc_tf= roc_curve(y_test, pred_probas_lr_sgdc_tf)\n",
    "\n",
    "roc_auc_lr_sgdc_tf = auc(fpr_lr_sgdc_tf,tpr_lr_sgdc_tf)\n",
    "plt.plot(fpr_lr_sgdc_tf,tpr_lr_sgdc_tf,label='area = %.2f' %roc_auc_lr_sgdc_tf)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.title('Stochastic Logistic Regression - tfidf (AUC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('auc_sdgc_tfidf.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) sgdc wit w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Logistic Regression) \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr_sgdc_w2v = SGDClassifier(loss='log', penalty='l1')\n",
    "lr_sgdc_w2v.fit(X_train_vectors_w2v, y_train)\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict_lr_sgdc_w2v = lr_sgdc_w2v.predict(X_test_vectors_w2v)\n",
    "y_prob_lr_sgdc_w2v = lr_sgdc_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict_lr_sgdc_w2v))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict_lr_sgdc_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred_probas_lr_sgdc_w2v = lr_sgdc_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "\n",
    "# Follwing cant be calculated due to multi-variables:\n",
    "fpr_lr_sgdc_w2v,tpr_lr_sgdc_w2v,thresholds_lr_sgdc_w2v = roc_curve(y_test, pred_probas_lr_sgdc_w2v)\n",
    "\n",
    "roc_auc_lr_sgdc_w2v = auc(fpr_lr_sgdc_w2v,tpr_lr_sgdc_w2v)\n",
    "print('AUC:', roc_auc_lr_sgdc_w2v)\n",
    "plt.plot(fpr_lr_sgdc_w2v,tpr_lr_sgdc_w2v,label='area = %.2f' %roc_auc_lr_sgdc_w2v)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.title('Stochastic Logistic Regression - Word2Vec (AUC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('auc_sdgc_w2v.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (lr)\n",
    "\n",
    "1. Feature Extraction Technique: tf-idf\n",
    "2. Feature Extraction Technique: w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) lr with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
    "\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict_lr_tfidf = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob_lr_tfidf= lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict_lr_tfidf))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict_lr_tfidf))\n",
    " \n",
    "fpr_lr_tfidf, tpr_lr_tfidf, thresholds_lr_tfidf = roc_curve(y_test, y_prob_lr_tfidf)\n",
    "roc_auc_lr_tfidf = auc(fpr_lr_tfidf, tpr_lr_tfidf)\n",
    "print('AUC:', roc_auc_lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_lr_tfidf, tpr_lr_tfidf, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression - tfidf (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_lr_tfidf.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) lr with w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression (W2v)\n",
    "\n",
    "lr_w2v=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_w2v.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict_lr_w2v = lr_w2v.predict(X_test_vectors_w2v)\n",
    "y_prob_lr_w2v = lr_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict_lr_w2v))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict_lr_w2v))\n",
    " \n",
    "fpr_lr_w2v, tpr_lr_w2v, thresholds_lr_w2v = roc_curve(y_test, y_prob_lr_w2v)\n",
    "roc_auc_lr_w2v = auc(fpr_lr_w2v, tpr_lr_w2v)\n",
    "print('AUC:', roc_auc_lr_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_lr_w2v, tpr_lr_w2v, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression - Word2Vec (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_lr_w2v.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (nb)\n",
    "\n",
    "1. Feature Extraction Technique: tf-idf\n",
    "2. Feature Extraction Technique: w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train) \n",
    "\n",
    " #Predict y value for test dataset\n",
    "y_predict_nb_tfidf= nb_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob_nb_tfidf = nb_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict_nb_tfidf))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict_nb_tfidf))\n",
    " \n",
    "fpr_nb_tfidf, tpr_nb_tfidf, thresholds_nb_tfidf = roc_curve(y_test, y_prob_nb_tfidf)\n",
    "roc_auc_nb_tfidf = auc(fpr_nb_tfidf, tpr_nb_tfidf)\n",
    "print('AUC:', roc_auc_nb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_nb_tfidf, tpr_nb_tfidf, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Naive Bayes - tdidf (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_nb_tdidf.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) nb with w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Gaussian Naive Bayes(w2v)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_w2v = GaussianNB()\n",
    "nb_w2v.fit(X_train_vectors_w2v, y_train) \n",
    "\n",
    "\n",
    " #Predict y value for test dataset\n",
    "y_predict_nb_w2v = nb_w2v.predict(X_test_vectors_w2v)\n",
    "y_prob_nb_w2v = nb_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict_nb_w2v))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict_nb_w2v))\n",
    " \n",
    "fpr_nb_w2v, tpr_nb_w2v, thresholds_nb_w2v = roc_curve(y_test, y_prob_nb_w2v)\n",
    "roc_auc_nb_w2v = auc(fpr_nb_w2v, tpr_nb_w2v)\n",
    "print('AUC:', roc_auc_nb_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_nb_w2v, tpr_nb_w2v, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Naive Bayes Gaussian - Word2Vec (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_nb_w2v.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (clf)\n",
    "\n",
    "1. Feature Extraction Technique: tf-idf\n",
    "2. Feature Extraction Technique: w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) clf with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using RandomForrest (tf-idf)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_tfidf = RandomForestClassifier(n_estimators = 100)\n",
    "clf_tfidf.fit(X_train_vectors_tfidf, y_train) \n",
    "\n",
    "\n",
    " #Predict y value for test dataset\n",
    "y_predict_clf_tfidf = clf_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob_clf_tfidf = clf_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict_clf_tfidf))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict_clf_tfidf))\n",
    " \n",
    "fpr_clf_tfidf, tpr_clf_tfidf, thresholds_clf_tfidf = roc_curve(y_test, y_prob_clf_tfidf)\n",
    "roc_auc_clf_tfidf = auc(fpr_clf_tfidf, tpr_clf_tfidf)\n",
    "print('AUC:', roc_auc_clf_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_clf_tfidf, tpr_clf_tfidf, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Random Forest Classifier - tdidf (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_clf_tfidf.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) clf with w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using RandomForrest (w2v)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_w2v = RandomForestClassifier(n_estimators = 100)\n",
    "clf_w2v.fit(X_train_vectors_w2v, y_train) \n",
    "\n",
    "\n",
    " #Predict y value for test dataset\n",
    "y_predict_clf_w2v = clf_w2v.predict(X_test_vectors_w2v)\n",
    "y_prob_clf_w2v = clf_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "\n",
    "print(classification_report(y_test,y_predict_clf_w2v))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict_clf_w2v))\n",
    " \n",
    "fpr_clf_w2v, tpr_clf_w2v, thresholds_clf_w2v = roc_curve(y_test, y_prob_clf_w2v)\n",
    "roc_auc_clf_w2v = auc(fpr_clf_w2v, tpr_clf_w2v)\n",
    "print('AUC:', roc_auc_clf_w2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_clf_w2v, tpr_clf_w2v, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Random Forest Classifier - Word2Vec (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_clf_w2v.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Multiclass Classification\n",
    "\n",
    "_Emoji dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "emoji_df = merging_labels_and_sentences('datasets/emoji/test_text', 'datasets/emoji/test_labels')\n",
    "\n",
    "X = emoji_df['tweet']\n",
    "y = emoji_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train_em, X_test_em, y_train_em, y_test_em = train_test_split(\n",
    "    X, y, test_size = 0.1, random_state = 13)\n",
    "\n",
    "X_train_tok_em= [nltk.word_tokenize(i) for i in X_train_em]  \n",
    "X_test_tok_em= [nltk.word_tokenize(i) for i in X_test_em]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "model_emoji = gensim.models.Word2Vec(X,min_count=1)\n",
    "w2v_emoji = dict(zip(model_emoji.wv.index_to_key, model_emoji.wv))      \n",
    "model_emoji.w = MeanEmbeddingVectorizer(w2v_emoji)\n",
    "\n",
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v_em = model_emoji.w.transform(X_train_tok_em)\n",
    "X_test_vectors_w2v_em = model_emoji.w.transform(X_test_tok_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Multiclassification: One vs. Rest Classifier (SVM)"
   ]
  },
  {
   "source": [
    "#### 1) SVM with w2v"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Creating the SVM model\n",
    "#model = OneVsRestClassifier(SVC())\n",
    "emoji_SVM = OneVsRestClassifier(GaussianNB())\n",
    "\n",
    "\n",
    "# Fitting the model with training data\n",
    "emoji_SVM.fit(X_train_vectors_w2v_em, y_train_em)\n",
    "   \n",
    "# Making a prediction on the test set\n",
    "prediction_SVM = emoji_SVM.predict(X_test_vectors_w2v_em)\n",
    "   \n",
    "# Evaluating the model\n",
    "print(f\"Test Set Accuracy : {accuracy_score(y_test_em, prediction_SVM) * 100} %\\n\\n\")\n",
    "print(f\"Classification Report : \\n\\n{classification_report(y_test_em, prediction_SVM)}\")"
   ]
  },
  {
   "source": [
    "## 2) Multiclassificarion: One vs. One Classifier (SVC)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1) SVG with w2v"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "emoji_SVC = OneVsOneClassifier(GaussianNB())\n",
    "\n",
    "\n",
    "# Fitting the model with training data\n",
    "emoji_SVC.fit(X_train_vectors_w2v_em, y_train_em)\n",
    "   \n",
    "# Making a prediction on the test set\n",
    "prediction_SVC = emoji_SVC.predict(X_test_vectors_w2v_em)\n",
    "   \n",
    "# Evaluating the model\n",
    "print(f\"Test Set Accuracy : {accuracy_score(y_test_em, prediction_SVC) * 100} %\\n\\n\")\n",
    "\n",
    "print(f\"Classification Report : \\n\\n{classification_report(y_test_em, prediction_SVC)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) kNN for Multiclassification"
   ]
  },
  {
   "source": [
    "#### 1) kNN with w2v"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "neigh_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh_knn.fit(X_train_vectors_w2v_em, y_train_em)\n",
    "pred_knn = neigh_knn.predict(X_test_vectors_w2v_em)\n",
    "print(f\"Test Set Accuracy : {accuracy_score(y_test_em, pred_knn) * 100} %\\n\\n\")\n",
    "print(f\"Classification Report : \\n\\n{classification_report(y_test_em, pred_knn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd07ca953050fbd6db0e15562356b1a786d9418e582a94adc67b248dc4dbecd989f",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "7ca953050fbd6db0e15562356b1a786d9418e582a94adc67b248dc4dbecd989f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}